{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be3fb63-87f3-4442-8b80-863938c4bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f87289-eba2-4745-8681-32afa852d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dpo_train.json','r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('dpo_eval.json','r') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "with open('train_1.json','r') as f:\n",
    "    train_1 = json.load(f)\n",
    "with open('train_2.json','r') as f:\n",
    "    train_2 = json.load(f)\n",
    "with open('train_3.json','r') as f:\n",
    "    train_3 = json.load(f)\n",
    "\n",
    "complete_train_sum = {\n",
    "    1:train_1,\n",
    "    2:train_2,\n",
    "    3:train_3\n",
    "}\n",
    "\n",
    "\n",
    "with open('eval_1.json','r') as f:\n",
    "    eval_1 = json.load(f)\n",
    "with open('eval_2.json','r') as f:\n",
    "    eval_2 = json.load(f)\n",
    "with open('eval_3.json','r') as f:\n",
    "    eval_3 = json.load(f)\n",
    "\n",
    "complete_eval_sum = {\n",
    "    1:eval_1,\n",
    "    2:eval_2,\n",
    "    3:eval_3\n",
    "}\n",
    "train_df = pd.read_csv('train_bos.csv')\n",
    "eval_df = pd.read_csv('eval_bos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28adfe23-2fde-4ab1-b321-e6f42a98b477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_keys = []\n",
    "for key in train_data:\n",
    "    if len(train_data[key])>10:\n",
    "        selected_keys.append(key)\n",
    "for key in eval_data:\n",
    "    if len(eval_data[key])>10:\n",
    "        selected_keys.append(key)\n",
    "len(selected_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b69dd7-e4f7-4c03-9014-e2b4b26a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample inputs, reference summaries, and candidate summaries\n",
    "data = [\n",
    "    {\n",
    "        \"input_text\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"reference_summary\": \"A quick fox jumps over a lazy dog.\",\n",
    "        \"candidate_summaries\": [\n",
    "            \"The quick fox leaped over the lazy dog.\",\n",
    "            \"A brown fox jumps over a dog.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"input_text\": \"Artificial intelligence is transforming industries.\",\n",
    "        \"reference_summary\": \"AI is changing industries.\",\n",
    "        \"candidate_summaries\": [\n",
    "            \"AI is revolutionizing the world.\",\n",
    "            \"Artificial intelligence is impacting all sectors.\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge(reference, candidates):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "    scores = []\n",
    "    for candidate in candidates:\n",
    "        score = scorer.score(reference, candidate)\n",
    "        rouge1 = score['rouge1'].fmeasure\n",
    "        rouge2 = score['rouge2'].fmeasure\n",
    "        rougeL = score['rougeL'].fmeasure\n",
    "        avg_score = (rouge1 + rouge2 + rougeL) / 3\n",
    "        scores.append(avg_score)\n",
    "    return scores\n",
    "\n",
    "# Create the dataset\n",
    "dataset = []\n",
    "for item in data:\n",
    "    input_text = item[\"input_text\"]\n",
    "    reference_summary = item[\"reference_summary\"]\n",
    "    candidate_summaries = item[\"candidate_summaries\"]\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = calculate_rouge(reference_summary, candidate_summaries)\n",
    "    \n",
    "    # Determine the preferred candidate\n",
    "    preferred_candidate = candidate_summaries[rouge_scores.index(max(rouge_scores))]\n",
    "    \n",
    "    # Add to dataset\n",
    "    for i, candidate in enumerate(candidate_summaries):\n",
    "        dataset.append({\n",
    "            \"Input Text\": input_text,\n",
    "            \"Reference Summary\": reference_summary,\n",
    "            \"Candidate Summary\": candidate,\n",
    "            \"ROUGE Score\": rouge_scores[i],\n",
    "            \"Preferred Candidate\": preferred_candidate if candidate == preferred_candidate else None\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Save as CSV\n",
    "# df.to_csv(\"preference_dataset.csv\", index=False)\n",
    "# print(\"Preference dataset created and saved as 'preference_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4812c1-44a5-4f45-a4df-30644bc8cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and eval datasets saved successfully!\n"
     ]
    }
   ],
   "source": [
    "dpo_dataset_train = {'ids':[],'prompt':[],\n",
    "             'rejected':[],\n",
    "             'chosen':[]}\n",
    "dpo_dataset_eval = {'ids':[],\n",
    "                    'prompt':[],\n",
    "             'rejected':[],\n",
    "             'chosen':[]}\n",
    "\n",
    "for idx , row in train_df.iterrows():\n",
    "    rank = train_data[row['video_ids']]\n",
    "    if len(rank)<10:\n",
    "        rank =[int(x) for x in rank.split(' ')]\n",
    "        dpo_dataset_train['ids'].append(row['video_ids'])\n",
    "        dpo_dataset_train['prompt'].append(row['transcripts'])\n",
    "        dpo_dataset_train['rejected'].append(complete_train_sum[rank[2]][row['video_ids']])\n",
    "        dpo_dataset_train['chosen'].append(complete_train_sum[rank[0]][row['video_ids']])\n",
    "    else:\n",
    "        dpo_dataset_train['ids'].append(row['video_ids'])\n",
    "        dpo_dataset_train['prompt'].append(row['transcripts'])\n",
    "        dpo_dataset_train['rejected'].append(complete_train_sum[1][row['video_ids']])\n",
    "        dpo_dataset_train['chosen'].append(row['human_summaries'])\n",
    "        \n",
    "\n",
    "for idx, row in eval_df.iterrows():\n",
    "    rank = eval_data[row['video_ids']]\n",
    "    if len(rank) < 10:\n",
    "        rank = [int(x) for x in rank.split(' ')]\n",
    "        dpo_dataset_eval['ids'].append(row['video_ids'])\n",
    "        dpo_dataset_eval['prompt'].append(row['transcripts'])\n",
    "        dpo_dataset_eval['rejected'].append(complete_eval_sum[rank[2]][row['video_ids']])\n",
    "        dpo_dataset_eval['chosen'].append(complete_eval_sum[rank[0]][row['video_ids']])\n",
    "    else:\n",
    "        dpo_dataset_eval['ids'].append(row['video_ids'])\n",
    "        dpo_dataset_eval['prompt'].append(row['transcripts'])\n",
    "        dpo_dataset_eval['rejected'].append(complete_eval_sum[1][row['video_ids']])\n",
    "        dpo_dataset_eval['chosen'].append(row['human_summaries'])\n",
    "\n",
    "# Save the train dataset\n",
    "with open('dpo_dataset_train.json', 'w') as train_file:\n",
    "    json.dump(dpo_dataset_train, train_file)\n",
    "\n",
    "# Save the eval dataset\n",
    "with open('dpo_dataset_eval.json', 'w') as eval_file:\n",
    "    json.dump(dpo_dataset_eval, eval_file)\n",
    "\n",
    "print(\"Train and eval datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d773ad-c33a-4d5e-93b2-89578188c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and eval datasets saved successfully in the updated format!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "curr_dpo_dataset_train = {'ids':[],'prompt':[],\n",
    "             'rank 1':[],\n",
    "             'rank 2':[],\n",
    "             'rank 3':[],\n",
    "            }\n",
    "curr_dpo_dataset_eval = {\n",
    "    'ids': [],\n",
    "    'prompt': [],\n",
    "    'rank 1': [],\n",
    "    'rank 2': [],\n",
    "    'rank 3': []\n",
    "}\n",
    "for idx , row in train_df.iterrows():\n",
    "    rank = train_data[row['video_ids']]\n",
    "    if len(rank)<10:\n",
    "        rank =[int(x) for x in rank.split(' ')]\n",
    "        curr_dpo_dataset_train['ids'].append(row['video_ids'])\n",
    "        curr_dpo_dataset_train['prompt'].append(row['transcripts'])\n",
    "        curr_dpo_dataset_train['rank 1'].append(complete_train_sum[rank[0]][row['video_ids']])\n",
    "        curr_dpo_dataset_train['rank 2'].append(complete_train_sum[rank[1]][row['video_ids']])\n",
    "        curr_dpo_dataset_train['rank 3'].append(complete_train_sum[rank[2]][row['video_ids']])\n",
    "\n",
    "for idx, row in eval_df.iterrows():\n",
    "    rank = eval_data[row['video_ids']]\n",
    "    if len(rank) < 10:\n",
    "        rank = [int(x) for x in rank.split(' ')]\n",
    "        curr_dpo_dataset_eval['ids'].append(row['video_ids'])\n",
    "        curr_dpo_dataset_eval['prompt'].append(row['transcripts'])\n",
    "        curr_dpo_dataset_eval['rank 1'].append(complete_eval_sum[rank[0]][row['video_ids']])\n",
    "        curr_dpo_dataset_eval['rank 2'].append(complete_eval_sum[rank[1]][row['video_ids']])\n",
    "        curr_dpo_dataset_eval['rank 3'].append(complete_eval_sum[rank[2]][row['video_ids']])\n",
    "\n",
    "\n",
    "# Save the train dataset\n",
    "with open('curr_dpo_dataset_train.json', 'w') as train_file:\n",
    "    json.dump(curr_dpo_dataset_train, train_file)\n",
    "\n",
    "# Save the eval dataset\n",
    "with open('curr_dpo_dataset_eval.json', 'w') as eval_file:\n",
    "    json.dump(curr_dpo_dataset_eval, eval_file)\n",
    "\n",
    "print(\"Train and eval datasets saved successfully in the updated format!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58feb044-4b14-4bc4-b968-4db818788ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python SMOL",
   "language": "python",
   "name": "smol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
