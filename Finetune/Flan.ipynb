{"cells":[{"cell_type":"code","execution_count":null,"id":"ae9dd96a-b29f-4b5f-8705-26b6ae815e09","metadata":{"id":"ae9dd96a-b29f-4b5f-8705-26b6ae815e09"},"outputs":[],"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] ='7'"]},{"cell_type":"code","execution_count":null,"id":"8f8d1a6d-7fce-4d7a-9161-e1dfb5942097","metadata":{"id":"8f8d1a6d-7fce-4d7a-9161-e1dfb5942097"},"outputs":[],"source":["from huggingface_hub import login\n","\n","login('Your Token')"]},{"cell_type":"code","execution_count":null,"id":"0fd20dea-9b29-454d-92d5-631330bb680a","metadata":{"scrolled":true,"id":"0fd20dea-9b29-454d-92d5-631330bb680a","outputId":"dd09ca6e-c249-4151-900b-2b13b1231de6"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]}],"source":["from transformers import T5ForConditionalGeneration, T5Tokenizer,  Trainer, TrainingArguments\n","\n","# Load the FLAN-T5 model and tokenizer\n","model_name =  \"soumagok/flan-t5-base-cnn_dailymail\" # You can choose other sizes like small, base, xl\n","model_name =  \"google/flan-t5-base\"\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = T5Tokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"id":"e44b9c8c-9f70-461a-8f14-bfced541c438","metadata":{"id":"e44b9c8c-9f70-461a-8f14-bfced541c438"},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","\n","train_df = pd.read_csv(\"train.csv\")\n","test_df = pd.read_csv(\"test.csv\")\n","eval_df = pd.read_csv(\"eval.csv\")\n","\n","# Filter DataFrames to retain only the required columns\n","train_filtered = train_df[[\"transcripts\", \"human_summaries\"]]\n","test_filtered = test_df[[\"transcripts\", \"human_summaries\"]]\n","eval_filtered = eval_df[[\"transcripts\", \"human_summaries\"]]\n","\n","# Convert the transformed data into Hugging Face datasets\n","train_dataset = Dataset.from_pandas(train_filtered)\n","test_dataset = Dataset.from_pandas(test_filtered)\n","eval_dataset = Dataset.from_pandas(eval_filtered)"]},{"cell_type":"code","source":["prefix = \"Summarize the given text: \"\n","def preprocess_function(examples):\n","    # Add prefix to inputs\n","    inputs = [prefix + doc for doc in examples[\"transcripts\"]]\n","\n","    # Tokenize inputs with padding and truncation\n","    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n","\n","    # Tokenize labels with padding and truncation\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"human_summaries\"], max_length=128, truncation=True, padding=\"max_length\")\n","\n","    # Assign tokenized labels to model_inputs\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","    return model_inputs\n","    return model_inputs\n","tokenized_train_data = train_dataset.map(preprocess_function, batched=True)\n","tokenized_test_data = test_dataset.map(preprocess_function, batched=True)\n","tokenized_eval_data =  eval_dataset.map(preprocess_function, batched=True)"],"metadata":{"id":"Uqwxs_PNq5Q-"},"id":"Uqwxs_PNq5Q-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"flan_no\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    #save_steps=500,\n","    #logging_dir=\"./logs\",\n","    logging_steps=10,\n","    push_to_hub=False,\n",")\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_data,\n","    eval_dataset=tokenized_eval_data,\n","    tokenizer=tokenizer,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n","\n","# # Save the model\n","# model.save_pretrained(\"./fine-tuned-bart-summarization\")\n","# tokenizer.save_pretrained(\"./fine-tuned-bart-summarization\")\n","\n","# # Evaluate the model\n","# metric = load_metric(\"rouge\")\n","\n","# def compute_metrics(eval_pred):\n","#     predictions, labels = eval_pred\n","#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","#     result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","#     return {k: round(v, 4) for k, v in result.items()}\n","\n","# trainer.evaluate(compute_metrics=compute_metrics)"],"metadata":{"id":"O4v97WewqzyE"},"id":"O4v97WewqzyE","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"5542ae96-486a-4600-9608-83d3f261383d","metadata":{"id":"5542ae96-486a-4600-9608-83d3f261383d"},"outputs":[],"source":["# trainer.push_to_hub()"]},{"cell_type":"code","execution_count":null,"id":"4dae1c49-f222-4d72-8110-b35291a3b694","metadata":{"id":"4dae1c49-f222-4d72-8110-b35291a3b694","outputId":"3f182c6c-3e3a-4349-eb51-636ad7cbc8d5"},"outputs":[{"data":{"text/plain":["('./flan_no_sum/tokenizer_config.json',\n"," './flan_no_sum/special_tokens_map.json',\n"," './flan_no_sum/spiece.model',\n"," './flan_no_sum/added_tokens.json')"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"./flan_no_sum\")\n","tokenizer.save_pretrained(\"./flan_no_sum\")"]},{"cell_type":"code","execution_count":null,"id":"f7da6f33-cc6e-4eb8-b570-7a4bc5f65275","metadata":{"id":"f7da6f33-cc6e-4eb8-b570-7a4bc5f65275"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python SMOL","language":"python","name":"smol"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}